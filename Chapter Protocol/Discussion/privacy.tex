\refstepcounter{subsection}\subsection*{\thesubsection\quad Privacy}\label{subsec:DiscussionPrivacy}

We describe privacy with three games, \cref{algo:ServerPrivacySearch}, \cref{algo:ServerPrivacyRetrieve} and \cref{algo:ClientPrivacycPDS}. To discuss privacy in the protocol, we show that an adversary cannot gain any significant advantage in any of the games. We consider each game individually, starting with the server's privacy in the search, then the retrieval, and lastly, the client's privacy in the protocol.

\paragraph*{Server privacy in the keyword search:} Let us consider \cref{algo:ServerPrivacySearch} for the keyword search protocol. In this game the server is the challenger and the client is the adversary. Recall that the adversary is a \acrshort{ppt} algorithm with access to the query functionality of the $ \Oracle $. In the query functionality, the oracle uses the $ \Garble $ algorithm to derive responses to the adversary. Its privacy is described such that if the adversary cannot distinguish between a response from $ \Garble $ of using the auxiliary information $ A $ and some random substitute $ \$ $, with an advantage greater than $ \mathcal{E} \left( \lambda \right) $, then we say that the search is private. The response to the adversary is the encoded auxiliary information $ A' $.

 Referencing the communication flow of the initiation of the keyword search, \cref{fig:OverviewInitKeywordSearch}, we have to show that $ \Garble $ produces $ A' $ such that it perfectly hides its contents since it is sent to the client. In $ \Garble $, the encryption of $ v'_j $ is produced for every value $ v_j $ in $ A' $. Here, it follows that every $ v'_j $ is pseudorandom and unique, as we instantiated $ \Encrypt $ with \acrshort{aes} and every input $ \Hash\left( v_j \right) $ was unique. For every set $ I_j $, an ephemeral key $ e_{2,j} $ is produced by encrypting $ v_j $ with $ e_2 $, giving the encryption of the set a unique encryption key, yielding a unique encryption of every $ I_j $ as each index $ \iota $ also is unique. Furthermore, we padded $ I_j $ with unique values, hence, all the values in $ A' $ are pseudorandom, padded to the same length, and therefore indistinguishable across iterations of $ \Garble $. 
 
 Next, we reference the communication flow of the transfer phase of the keyword search in the overview, \cref{fig:OverviewTransferKeywordSearch}. We do this to show the correctness of $ \Search $ and to verify to ourselves that no additional information about $ A' $ is leaked. The encryption of the client's search query $ q'_i $ under $ e_1 $ and $ e_2 $ is done with an \acrshort{oprf}, and the \acrshort{oprf} is realized using generic \acrshort{mpc} thereby its privacy follows from it. The last thing we must show is that $ \Search $ reveals no more information than a single set $ I_j $. The client can only match $ q_{e_1} $ with one or less $ v'_j $ in $ A' $ at a time, and given that it has a positive match, it can only construct the ephemeral key $ e_{2, j} $ for that set of indices $ I'_j $. Thus, the client can, at most, decrypt one set of indices in $ A' $ per transfer. The size of $ A' $ reveals information about $ m $ and $ n $, but recall that the client already knows these values from the protocol. Further, the values of the indices that the client learns between sessions cannot be correlated as $ D $ is shuffled in $ \Setup $.

\paragraph*{Server privacy in the semantic search:} Let us consider \cref{algo:ServerPrivacySearch} for the semantic search.  In this game the server is the challenger and the client is the adversary.

Recall the communication flow in the initiation, \cref{fig:OverviewInitSemanticSearch}, shows that no data is exchanged between the client and server. In the transfer phase the communication flow, \cref{fig:OverviewTransferSemanticSearch}, shows that $ \Search $ is computed in \acrshort{mpc}. Therefore, it follows from \acrshort{mpc} that $ \Search $ reveals no information about $ A $ (excluding the values of $ m $ and $ n $); thus, the client only learns the set of indices $ I_j $, showing that no additional information is leaked.

\paragraph*{Server privacy in the retrieval:} Let us consider \cref{algo:ServerPrivacyRetrieve} for the \acrshort{ot} protocol. In this game the server is the challenger and the client is the adversary. Recall that the adversary is a \acrshort{ppt} algorithm with access to the query functionality of the $ \Oracle $. In the query functionality, the oracle uses the $ \Retrieve $ algorithm to derive responses to the adversary. Its privacy is described such that if the adversary cannot distinguish between a response from $ \Retrieve $ of its original query item $ I'_i $ and some random substitute $ \$ $ with an advantage greater than $ \mathcal{E} \left( \lambda \right) $ then we say that $ \Retrieve $ is private.

Recall that $ \Retrieve $ fetches only the associated record with the indices and returns that ciphertext $ F'_i $ to the client. Hence, it follows that $ \Retrieve $ reveals no other information about the database as it precisely fetches the relevant records. In $ \PreProcess $ each record is encrypted using \acrshort{ctr}-\acrshort{aes} and shuffled randomly according to some permutation. Additional, the shuffling is done with an oblivious sorting algorithm which has the same access patterns on the records regardless of the permutation. The swaps are made private by the MPC-based PS protocol, which performs the encryption and swapping using generic MPC, so its privacy follows from there.

\paragraph*{Client privacy in the protocol:} Let us consider \cref{algo:ClientPrivacycPDS} for the protocol. In this game the client is the challenger and the server is the adversary. Recall that the adversary is a \acrshort{ppt} algorithm with access to the query functionality of the $ \Oracle $. In the query functionality, the oracle uses the $ \Encode $ algorithm to derive responses to the adversary. Its privacy is described such that if the adversary cannot distinguish between a response of its original query item $ I_i $ and some random substitute $ \$ $ with an advantage greater than $ \mathcal{E} \left( \lambda \right) $ then we say that protocol is private for the client. The response to the adversary input $ I'_i $ is a set of encoded indices, achieved by running $ \Encode $ to encode them.

Referring to the communication flow in the transfer phase of both the keyword and semantic search, \cref{fig:OverviewTransferKeywordSearch} and \cref{fig:OverviewTransferSemanticSearch}, the client's privacy follows from generic \acrshort{mpc}. Leaving the remaining information the client sends to the server in the $ \PreProcess $, \cref{fig:OverviewPreProcess}. The $ \PreProcess $ algorithm is simplified in the overview, but recall that the client uses an oblivious sorting algorithm in combination with \acrshort{ps} to shuffle and encrypt the database. In the generic \acrshort{mpc}-based \acrshort{ps} protocol, \cref{algo:ClientBooleanPS} and \cref{algo:ServerBooleanPS}, $\CTR $-$ \Encrypt$ is used, which provides \acrshort{indcpa} security, thus making the encrypted records indistinguishable from the server. Following from the oblivious sorting algorithm is that the access pattern the client uses reveals no information about the swaps it performs. Thus, the random permutation $ \pi $ puts the records in a random order such that the original location of the records cannot be correlated with the new ones by the server. Therefore, using $ \pi $ to encode the set of indices $ I_i $ in $ \Encode $ reveals no information about the indices. Further, recall that dummy indices are used to pad each set of encoded records in $ \Encode $. Hence, the set of encoded indices $ I'_i $ reveals no information about the records retrieved and the result of the search, given the set of dummy indices $ \eta $ is not exhausted.


\paragraph*{Downsides to the privacy description:} In our privacy descriptions we deviated from the \acrshort{indcpa} definition, often implicitly referred to as semantic security, by introducing an encoding oracle. By doing so, we lose the multi-tenancy property that implicitly follows from \acrshort{pir}'s privacy definition \cite{CCS:Henry17}. To demonstrate why, let us consider the proposed protocol in our work. In it, $ \Encode $ uses a permutation to encode a set of indices sent to the server, something that works with a single client as it keeps track of its requests and never uses the same indices. With multiple clients, under the assumption that the clients do not cooperate, this becomes a problem as $ \Encode $ produces the same output for clients who want to retrieve the same records, which, when sent to the server reveals that those clients have equivalent searches. Thus, the key observation is that $ \Encode $ should satisfy a non-deterministic semantic security definition to allow for multi-tenancy, which implicitly brings with it that $ \Retrieve $ also has to be non-deterministic. Depending on the protocol, $ \Garble $ also could be non-deterministic as encoding the database deterministic could reveal information about whether the contents of the database has changed. For an instance in our protocol if the client receives an identical indexing on two different initiations of the database it can infer that no new records were added or deleted.